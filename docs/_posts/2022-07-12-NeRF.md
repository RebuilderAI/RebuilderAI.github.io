---
date: 2022-07-12
layout: post
title: 'NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis'
subtitle: NeRF introduce
description: Tech blog
image: https://user-images.githubusercontent.com/55485826/178452238-a4eb2b1b-07f2-49d5-ab59-1dfa829be00e.png
category: Reconstruction, Novel View Synthesis
tags:
  - vision
  - 3d reconstruction
  - graphics
use_math: true
author: jgnooo
---

# Neural Radiance Fields
---

오늘 RebuilderAI AI팀에서 소개할 기술은 요즘 Novel view synthesis 분야에서 많은 인기를 끌고 있는 Neural Radiance Fields(NeRF) 입니다.

Novel view synthesis란 새로운 시점(viewpoint)에서 보여지는 이미지를 rendering하는 것을 말합니다. 가상 / 증강 현실, 메타버스에 대한 관심이 높아짐에 따라 view synthesis에 대한 관심, 연구도 함께 집중되고 있으며, NeRF는 특히 많은 관심을 받아 다양한 후속 연구들이 쏟아져 나오고 있습니다. 

그럼, 지금부터 NeRF란 기술이 생소하신 분들을 위해 NeRF가 어떤 것인지, 어떤 과정으로 동작하는지 소개를 하도록 하겠습니다.

## 1. Differentiable rendering
---
<!-- 기본적으로 **Rendering**이란 형상(geometry), 재질(material), 빛(light), 카메라(camera) 등 scene parameter들에 의해 정의된 3차원 장면에 대한 이미지를 생성하는 프로세스를 말합니다. 반면, **Inverse rendering**은 2D 이미지로부터 scene에 대한 특성, parameter를 예측 / 추론하는 것을 말합니다. -->
**Differentiable rendering**이란 간단하게 말해서, 컴퓨터 그래픽스에서의 rendering 프로세스를 기반으로 scene 파라미터를 통해 생성한 이미지로부터 gradient를 계산하여 최적화하는 프로세스입니다. 
![Differentiable Renderer 최적화 과정](https://user-images.githubusercontent.com/55485826/178452142-ebccce87-3229-422a-bd76-708c001e32c4.png)
> Differentiable renderer 최적화 과정

![이미지 기반 Differentiable Rendering 최적화 과정](https://user-images.githubusercontent.com/55485826/178452202-2cae7e06-248c-412b-9ef0-47567f653efc.png)
> 이미지 기반 Differentiable rendering 최적화 과정

이 프로세스를 통해서 scene 파라미터와 2D 이미지 사이의 관계를 모델링할 수 있고, 다양한 컴퓨터 그래픽스에서의 inverse rendering을 비롯한 다양한 문제들을 해결할 수 있습니다.

<!-- - **Why Use Differentiable Rendering?**
    - Inverse rendering 문제를 해결하기 위해 사용
    - Rendering 프로세스를 machine learning 파이프라인에 적용해 문제 해결 -->

## 2. Neural Radiance Fields 란?
---

> **NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis**   
*Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi, Ren Ng*   
*UC Berkeley, Google Research, UC San Diego*   
*ECCV 2020*   
> 

![Reference: NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis](https://user-images.githubusercontent.com/55485826/178452238-a4eb2b1b-07f2-49d5-ab59-1dfa829be00e.png)
> 이미지 참조: NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis

### 2-1. Ray casting
---

### 2-2. Volume rendering
---

### 2-3. Positional encoding
---

### 2-4. Ray sampling
---

    - 일반적인 Computer vision에서의 CNN 기반 이미지 인식 기술과 달리 이미지, 카메라 파라미터를 활용한 Ray 기반 방법
        - Neural Rendering: Classic computer graphics 기술 (volume rendering) 과 딥러닝 (MLP; Multi Layer Perceptron) 을 결합
    - Nerural Radiance Fields: Scene representation → Color $c$, Density $\sigma$

- **How to training**
    1. 카메라 파라미터를 이용해 Ray 생성 (Ray origin; 카메라 위치, Ray direction; 카메라가 보는 방향)
    2. Volume을 통과하는 ray에서 3차원 포인트 sampling
    3. Positional encoding
    4. 딥러닝 네트워크 입력
    5. MLP를 통해 color, density 계산
    6. Volume rendering으로 최종 pixle color 예측, Rendering loss 계산

## 3. NeRF의 한계
---

## 4. 앞으로의 방향성
---
