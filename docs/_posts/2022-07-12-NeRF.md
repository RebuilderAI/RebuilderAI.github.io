---
date: 2022-07-12
layout: post
title: 'NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis'
subtitle: NeRF introduce
description: Tech blog
image: https://user-images.githubusercontent.com/55485826/178452238-a4eb2b1b-07f2-49d5-ab59-1dfa829be00e.png
category: Reconstruction, Novel View Synthesis
tags:
  - vision
  - 3d reconstruction
  - graphics
use_math: true
author: jgnooo
---

# Neural Radiance Fields

---

오늘 RebuilderAI AI팀에서 소개할 기술은 요즘 Novel view synthesis 분야에서 많은 인기를 끌고 있는 Neural Radiance Fields(NeRF) 입니다.

Novel view synthesis란 새로운 시점(viewpoint)에서 보여지는 이미지를 rendering하는 것을 말합니다. 가상 / 증강 현실, 메타버스에 대한 관심이 높아짐에 따라 view synthesis에 대한 관심, 연구도 함께 집중되고 있으며, NeRF는 특히 많은 관심을 받아 다양한 후속 연구들이 쏟아져 나오고 있습니다. 

지금부터 NeRF에 대해 소개하도록 하겠습니다.

# 1. Differentiable rendering

---

- **Rendering** :
    - 형상(geometry), 재질(material), 빛(light), 카메라(camera) 등에 의해 정의된 3차원 장면에 대한 이미지를 생성
    
- **Inverse Rendering** :
    - 입력 이미지로부터 Scene의 특성, 파라미터 (형상, 재질, 빛, 카메라 등)를 예측 / 추론

- **Differentiable Rendering** :
    
    ![- Differentiable Renderer 최적화 과정](https://user-images.githubusercontent.com/55485826/178452142-ebccce87-3229-422a-bd76-708c001e32c4.png)
    
    - Differentiable Renderer 최적화 과정
    
    ![이미지 기반 Differentiable Rendering 최적화 과정](https://user-images.githubusercontent.com/55485826/178452202-2cae7e06-248c-412b-9ef0-47567f653efc.png)
    
    이미지 기반 Differentiable Rendering 최적화 과정
    
    - Scene 파라미터와 관측된 이미지 사이의 관계를 모델링
    - Scene 파라미터를 통해 rendering된 결과 이미지로부터 gradient를 계산해 최적화
    
- **Why Use Differentiable Rendering?**
    - Inverse rendering 문제를 해결하기 위해 사용
    - Rendering 프로세스를 machine learning 파이프라인에 적용해 문제 해결

# Neural Radiance Fields

---

> **NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis**
*Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi, Ren Ng*
*UC Berkeley, Google Research, UC San Diego
ECCV 2020*
> 
- **What is NeRF?**
    
    ![Reference: NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis](https://user-images.githubusercontent.com/55485826/178452238-a4eb2b1b-07f2-49d5-ab59-1dfa829be00e.png)
    
    Reference: NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis
    
    - 일반적인 Computer vision에서의 CNN 기반 이미지 인식 기술과 달리 이미지, 카메라 파라미터를 활용한 Ray 기반 방법
        - Neural Rendering: Classic computer graphics 기술 (volume rendering) 과 딥러닝 (MLP; Multi Layer Perceptron) 을 결합
    - Nerural Radiance Fields: Scene representation → Color $c$, Density $\sigma$

- **How to training**
    1. 카메라 파라미터를 이용해 Ray 생성 (Ray origin; 카메라 위치, Ray direction; 카메라가 보는 방향)
    2. Volume을 통과하는 ray에서 3차원 포인트 sampling
    3. Positional encoding
    4. 딥러닝 네트워크 입력
    5. MLP를 통해 color, density 계산
    6. Volume rendering으로 최종 pixle color 예측, Rendering loss 계산
    
- **Volume rendering**
    - 

목차

1. Differentiable rendering에 대해
2. NeRF란?
    1. ray casting
    2. volume rendering
    3. positional encoding
    4. ray sampling
3. NeRF의 한계
4. 앞으로의 방향성