---
date: 2022-07-26
layout: post
title: "Surface Reconstruction: IDR"
subtitle: Tech blog
description: NeurIPS 2020 IDR
image: https://user-images.githubusercontent.com/55485826/180905399-7b6bd602-3a08-440e-a2c3-b8145c1a0e51.png
category: Reconstruction
tags:
  - Vision
  - 3D reconstruction
  - Graphics
author: jgnooo
---

# Surface Reconstruction
---
이번주에 RebuilderAI R&D팀에서 소개할 내용은 Deep learning 기반 Surface reconstruction 기술입니다.

지난번에 포스팅한 NeRF처럼, 여러 시점에서 촬영된 이미지와 카메라 파라미터를 입력으로 사용하지만, Surface reconstruction에서는 3D surface를 잘 복원하는 것이 주된 목적이라는 점에서 차이를 보입니다.

오늘 소개할 기술은 2020년 NeurIPS에서 소개된 **IDR: Multiview Neural Surface Reconstruction by Disentangling Geometry and Appearance** 논문에서 제안하는 방법입니다.

지금부터, 이미지들만을 가지고 어떻게 3차원 모델을 복원하는지 IDR(Implicit Differentiable Renderer) 기술을 가지고 설명하도록 하겠습니다.

## 3D geometry representation
---
최근 컴퓨터 비전 / 그래픽스 분야에서 2차원 이미지로부터 3차원 Shape을 복원하는 문제를 풀기 위해서 (딥러닝 기반) Differentiable rendering 방법을 많이 사용하고 있으며, 3D geometry를 잘 표현할 수 있도록 최적화하는 방법을 주로 사용합니다. 이 때 3D geometry를 표현하는 방법은 Point cloud, Triangle mesh 그리고 Implicit representation 등이 있습니다. 여기서 Implicit한 표현 방식은 Volumetric grid를 사용하거나(NeRF), Zero level set(SDF)으로 표현하는 방법이 있습니다.
![3d_geometry](https://user-images.githubusercontent.com/55485826/180927513-b26a29fd-5402-471a-be5a-3467f38cab6b.png)
    _그림 1) Point cloud와 Triangle mesh_

IDR에서는 3D geometry를 표현하기위해 Implicit한 zero level set(SDF) 방법을 사용하였습니다. 이러한 Implicit한 방법을 통해서, 임의의 Shape, Topology를 가진 3D surface를 보다 유연하고 잘 표현할 수 있게 되었습니다. 그럼 이제 좀 더 자세하게 딥러닝을 기반으로 어떻게 3D geometry를 Implicit하게 표현하고 Appearance는 어떻게 처리되는지 자세하게 설명하도록 하겠습니다.

## Implicit Neural Representation
---
먼저 딥러닝 기반 Implicit representation에 대해 좀 더 말씀드리겠습니다.

일반적인 Neural network는 Discrete한 정보를 기반으로 Parameterize하게 됩니다 (e.g. 이미지의 픽셀이 주어지면 Depth를 예측). 이와 반대로 Implicit (neural) representation은 Continuous한 정보를 Parameterize 할 수 있습니다. 이미지를 예로 들면, 이미지 상의 x, y 좌표가 주어지면 이 좌표에 해당하는 RGB로 매핑하는 함수가 Implicit representation의 한 예입니다. 즉, Implicit representation을 위해 Neural network를 학습한 다는 것은 어떤 좌표가 주어졌을 때(이미지를 예로 들면) 이미지를 표현할 수 있는 함수가 되도록 Neural network의 파라미터를 학습한다는 것 입니다.

IDR에서는 이러한 Implicit representation의 개념을 활용해 어떤 3D 좌표가 주어졌을 때 이에 대응하는 Shape과 Appearance를 출력할 수 있도록하는 Neural network architecture를 설계하였습니다. IDR의 구조는 크게 Implicit neural representation network, Sampling network, Neural renderer로 이루어져있습니다. 지금부터 각각에 대해 소개하도록 하겠습니다.

### Geometry
---
가장 먼저 Geometry를 표현하는 Network 입니다.

이 Network에서는, SDF를 Implicit한 Zero level set(Implicit representation)으로 모델링합니다. 여기서 SDF란 어떤 좌표가 주어졌을 때 Surface와의 거리를 나타내는 함수로, 그 좌표가 Surface의 내부인지, 외부인지를 부호를 통해 표현하며, Surface인 경우에는 0인 함수입니다.
![SDF](https://user-images.githubusercontent.com/55485826/180936311-a37961e2-538d-4704-b4e2-45ef1f5e8d4c.png)
    _그림 2) Surface SDF 예시. 빨간 영역은 외부(+), 파란 영역은 내부(-)_

이와 같이 Network가 좌표가 주어졌을 때 정확한 Surface를 표현할 수 있도록(i.e. SDF = 0) Implicit representation을 학습하게 됩니다.

### Differentiable Intersection of Viewing Direction and Geometry
---
IDR은 딥러닝을 기반으로 한 Differentiable rendering 방법입니다. 그렇기 때문에 Geometry network에서 Surface point(Intersection point)를 적용할 때 Intersection point를 구하는 식과 초기 파라미터와 Geometry network를 통한 Intersection point가 정확하게 일치하는지를 계산하여 Sampling을 진행합니다. 이 과정을 Samping network로 구현하여 진행하였습니다. 이 과정에서 Normal 벡터를 구해야하는데, 여기서는 Differentiable depth(SDF)를 미분하는 방식으로 Normal을 계산하여 사용합니다.

### Appearance
---
마지막으로, IDR에서 Surface의 Radiance를 어떻게 모델링하는지 설명하겠습니다.

IDR에서는 빛이 Surface로 들어올 때 어떻게 반사되는지(Reflected), 그리고 방출되는지(Emitted)를 Bidirectional Reflectance Distribution Function(BRDF)을 사용해 표현하고자 했습니다. BRDF는 빛이 들어오는 각도, 반사되어 나가는 각도와 해당 Surface에서의 Normal을 알고 있을 때 반사율을 예측하기 위한 함수입니다. 이 때 빛이 반사되어 나가는 각도는 빛이 반사되어 카메라로 들어간다고 가정을 합니다. Surface에서 방출되는 빛 그리고 BRDF를 통해 예측할 수 있는 반사율과 들어오는 빛을 이용한 **Rendering equation**을 통해 카메라에 도달하는 빛의 양을 계산할 수 있습니다. IDR은 이 Rendering equation을 Neural network를 통해 모델링해 최종 Color 값을 예측하도록 하였습니다.

#### Rendering Equation
---
Rendering equation(식 1)은 컴퓨터 그래픽스의 Renderer에서 널리 사용되는 수식입니다. 이 식에 대해서 간략하게 설명하겠습니다.
![rendering_equation](https://user-images.githubusercontent.com/55485826/180945082-42fae0bb-055a-4a53-a8f7-1998389a2397.png)
    _식 1) Rendering equation_

식이 조금 복잡해보이지만 간단하게 표현하면 다음과 같습니다.

**Surface point에서 카메라로 향하는 전체 빛** = **Surface point에서 카메라로 방출하는 빛** + **적분(반사율 * Surface point로 들어오는 빛 * 각도에 따라 Surface point로 들어오는 빛의 양을 조절하기 위한 factor)** 여기서 적분(반사율 * Surface point로 들어오는 빛 * 각도에 따라 Surface point로 들어오는 빛의 양을 조절하기 위한 factor)의 결과는 반사되는 빛입니다. (이 식에서의 빛의 양을 조절하는 factor는 기울기에 따라 들어오는 빛의 양이 작아지거나 더 많이 들어오는 경우를 수학적으로 정의하기 위해 사용한 것 입니다.)

또한, 반사율이라 표현한 부분은 BRDF를 통해 얻을 수 있으며, 입사각과 반사각이 주어졌을 때 반사각으로 반사될 확률, 즉 반사율을 계산하는 함수 입니다.

## IDR Result
---
![result](https://user-images.githubusercontent.com/55485826/180943207-dc257b2a-0c1c-4750-bc48-39ae2404df1b.gif)
    _그림 3) IDR을 통해 복원한 결과_

그림 3)은 IDR 방법을 통해 복원한 결과를 보여주고 있습니다. 3D reconstruction 분야에서 많이 사용되는 공개 데이터셋 DTU 이미지를 사용하여 복원한 결과로, 이 전에 제시된 방법인 DVR이나 딥러닝 기반 방식이 아닌 전통적인 방법을 기반으로 한 Colmap에 비해 더 잘 복원된 것을 확인할 수 있습니다.

## 마무리
---
IDR은 3D reconstruction을 위해 제시된 딥러닝 기반 방법입니다. 이미지와 카메라 정보만을 가지고 상당히 잘 복원된 것을 확인할 수 있었습니다. 또한, 컴퓨터 그래픽스에서 사용되는 Rendering equation을 모델링하여 반사율을 고려했다는 점에서 정말 좋은 기술이였습니다. 2020년 NeurIPS에 게재된 조금은 이전 방법이지만, 여기서 고려한 아이디어나 설계 방식들을 참고하면 좀 더 뛰어난 복원 성능에 도달할 수 있을 것 같습니다.

이만 IDR 기술에 대한 소개를 마치도록 하겠습니다. 감사합니다.


#### 참고 자료
> **그림 1)** https://towardsdatascience.com/3d-object-classification-in-6-steps-using-kaolin-and-colab-9ecb079143a8   
> **그림 2)** Implicit Geometric Regularization for Learning Shapes   
> **그림 3)** https://lioryariv.github.io/idr/   